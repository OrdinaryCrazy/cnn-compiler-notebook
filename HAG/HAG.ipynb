{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as pyg\n",
    "import numpy as np\n",
    "import torch\n",
    "import heapq\n",
    "import math\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.utils import scatter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAG(object):\n",
    "    '''\n",
    "        Hierarchically Aggregated Computation Graphs\n",
    "        Version: 0.0\n",
    "        Programmer: Jingtun ZHANG\n",
    "        Last modified: Jingtun ZHANG 20190804\n",
    "    '''\n",
    "    def __init__(self, x, edge_index, ha_proportion=0.25, redundancy_threshold=1, \n",
    "                 aggr='add', flow='source_to_target'):\n",
    "        '''\n",
    "            input:\n",
    "                x:  [torch.tensor shape (N, d)]\n",
    "                    origin nodes \n",
    "                edge_index: [torch.tensor COO format shape ( 2 * E, 2)]\n",
    "                    origin edges \n",
    "                ha_proportion: [scalar 0~1]\n",
    "                    proportion of aggregated nodes number to origin nodes number \n",
    "                redundancy_threshold: [scalar]\n",
    "                    minimum redundancy threshold aggregated node generation \n",
    "                aggr: [str 'add' or 'mean' or 'max']\n",
    "                    aggregation scheme to use\n",
    "                flow: [str 'source_to_target' or 'target_to_source']\n",
    "                    flow direction of message passing\n",
    "            output:\n",
    "                None\n",
    "        '''\n",
    "        self.h = x\n",
    "        self.x = x\n",
    "        self.V = x.shape[0]\n",
    "        # coo format edge index\n",
    "        ############################################################\n",
    "        # ATTENTION: HERE IS COMPUTATION GRAPH (DIRECTED GRAPH)    #\n",
    "        #            NOT TOPOLOGY GRAPH                            #\n",
    "        # [ [ target_i_0, target_i_1, ... , target_i_2E ]          #\n",
    "        #   [ source_i_0, source_i_1, ... , source_i_2E ] ]        #\n",
    "        ############################################################\n",
    "        self.edge_index = edge_index\n",
    "        self.capacity = np.ceil(x.shape[0] * ha_proportion)\n",
    "        # aggregated nodes [torch.tensor shape (N_A, d)]\n",
    "        # self.ha = torch.FloatTensor(0, x.shape[1])\n",
    "        self.redundancy_threshold = redundancy_threshold\n",
    "        # in Version 0.0 only consider 'add'\n",
    "        self.aggr = aggr\n",
    "        # in Version 0.0 only consider 'source_to_targets'\n",
    "        self.flow = flow\n",
    "    def graph_to_hag(self):\n",
    "        '''\n",
    "            build HAG at preprocessing stage\n",
    "            input:\n",
    "                None\n",
    "            output:\n",
    "                None\n",
    "        '''\n",
    "        while self.h.shape[0] - self.V < self.capacity :\n",
    "            v_i, v_j, max_r = self.max_redundancy()\n",
    "            log = 'redundancy:{:4d}, {:4d} / {:4d} '\n",
    "            print(log.format(int(max_r), int(self.h.shape[0]-self.V),int(self.capacity)),end = \"\\r\")\n",
    "            if max_r > self.redundancy_threshold :\n",
    "                newPoint = self.h[v_i] + self.h[v_j]\n",
    "                newPointIndex = self.h.shape[0]\n",
    "                # insert new point\n",
    "                newPoint = newPoint.view(1,self.h.shape[1])         \n",
    "                self.h = torch.cat([self.h, newPoint], 0)\n",
    "                self.edge_index = torch.cat([\n",
    "                    self.edge_index.t(),\n",
    "                    torch.tensor([\n",
    "                      # [v_i, newPointIndex],\n",
    "                        [newPointIndex, v_i],\n",
    "                      # [v_j, newPointIndex],\n",
    "                        [newPointIndex, v_j]\n",
    "                    ], dtype=torch.long)\n",
    "                ]).t().contiguous()\n",
    "                \n",
    "                for i in range(self.h.shape[0] - 1) :\n",
    "                    # common neighbor judge\n",
    "                    v_i_con = ( (self.edge_index.t()[:,0] == i  )\n",
    "                               &(self.edge_index.t()[:,1] == v_i) ).nonzero().shape[0] == 1\n",
    "                    v_j_con = ( (self.edge_index.t()[:,0] == i)\n",
    "                               &(self.edge_index.t()[:,1] == v_j) ).nonzero().shape[0] == 1\n",
    "                    if v_i_con and v_j_con :\n",
    "                        #-------------------------------------------------------------\n",
    "                        # index = ( (self.edge_index.t()[:,0] == v_i)\n",
    "                        #          &(self.edge_index.t()[:,1] == i) ).nonzero().item()\n",
    "                        # self.edge_index = torch.cat([\n",
    "                        #     self.edge_index.t()[:index],\n",
    "                        #     self.edge_index.t()[index+1:]\n",
    "                        # ]).t().contiguous()\n",
    "                        #-------------------------------------------------------------\n",
    "                        # index = ( (self.edge_index.t()[:,0] == v_j)\n",
    "                        #          &(self.edge_index.t()[:,1] == i) ).nonzero().item()\n",
    "                        # self.edge_index = torch.cat([\n",
    "                        #     self.edge_index.t()[:index],\n",
    "                        #     self.edge_index.t()[index+1:]\n",
    "                        # ]).t().contiguous()\n",
    "                        #-------------------------------------------------------------\n",
    "                        index = ( (self.edge_index.t()[:,0] == i  )\n",
    "                                 &(self.edge_index.t()[:,1] == v_i)).nonzero().item()\n",
    "                        self.edge_index = torch.cat([\n",
    "                            self.edge_index.t()[:index],\n",
    "                            self.edge_index.t()[index+1:]\n",
    "                        ]).t().contiguous()\n",
    "                        #-------------------------------------------------------------\n",
    "                        index = ( (self.edge_index.t()[:,0] == i  )\n",
    "                                 &(self.edge_index.t()[:,1] == v_j)).nonzero().item()\n",
    "                        self.edge_index = torch.cat([\n",
    "                            self.edge_index.t()[:index],\n",
    "                            self.edge_index.t()[index+1:]\n",
    "                        ]).t().contiguous()\n",
    "                        #-------------------------------------------------------------\n",
    "                        self.edge_index = torch.cat([\n",
    "                            self.edge_index.t(), \n",
    "                        #     torch.tensor([ [ i, newPointIndex ], [ newPointIndex, i ] ],\n",
    "                        #                  dtype=torch.long)]).t().contiguous()\n",
    "                            torch.tensor([[i,newPointIndex]],dtype=torch.long)]).t().contiguous()\n",
    "                        #-------------------------------------------------------------\n",
    "            else:\n",
    "                break\n",
    "        print(\"hag building finished\")\n",
    "        return\n",
    "\n",
    "    def hag_aggregate(self):\n",
    "        '''\n",
    "            compute embedding of aggregate node every iteration \n",
    "            input:\n",
    "                None\n",
    "            output:\n",
    "                None\n",
    "        '''\n",
    "        iter_times = int(np.ceil(math.log2(self.capacity)))\n",
    "        out = self.h.clone()\n",
    "        for i in range(iter_times):\n",
    "            out = scatter_(self.aggr, out, self.edge_index[0])\n",
    "            out = torch.cat(self.h[:V], out[V:])\n",
    "        self.h = out\n",
    "        self.x = self.h[:V]\n",
    "\n",
    "#     def hag_aggregate_grad(self):\n",
    "#         '''\n",
    "#             compute the gradients of hag_aggregate for back propagation\n",
    "#             not implement in Version 0.0\n",
    "#         '''\n",
    "\n",
    "    def max_redundancy(self):\n",
    "        '''\n",
    "            find max redundancy node pair and return it\n",
    "            input:\n",
    "                None\n",
    "            output: \n",
    "                v_i [scalar], v_j [scalar], max_r [scalar]\n",
    "        '''\n",
    "        all_nodes_num = self.h.shape[0]\n",
    "        coo_edge_index = coo_matrix(( np.ones(self.edge_index.shape[1]), \n",
    "                                     (self.edge_index[0], self.edge_index[1])), \n",
    "                                     shape=(all_nodes_num, all_nodes_num))\n",
    "        csr_edge_index = coo_edge_index.tocsr()\n",
    "        common_neighbor_num = csr_edge_index.transpose().dot(csr_edge_index)\n",
    "        common_neighbor_num.setdiag(0)\n",
    "        max_num_flat_index = common_neighbor_num.argmax()\n",
    "        v_i, v_j = (int(max_num_flat_index/all_nodes_num), int(max_num_flat_index%all_nodes_num))\n",
    "        max_r = common_neighbor_num.max()\n",
    "        \n",
    "        return v_i, v_j, max_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redundancy:  23,  109 /  183 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-224e5af3bc5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# val_f1 = test(val_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-224e5af3bc5f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-224e5af3bc5f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mha_proportion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# build hag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_to_hag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5c8713c8391e>\u001b[0m in \u001b[0;36mgraph_to_hag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0;31m# common neighbor judge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     v_i_con = ( (self.edge_index.t()[:,0] == i  )\n\u001b[0;32m---> 78\u001b[0;31m                                &(self.edge_index.t()[:,1] == v_i) ).nonzero().shape[0] == 1\n\u001b[0m\u001b[1;32m     79\u001b[0m                     v_j_con = ( (self.edge_index.t()[:,0] == i)\n\u001b[1;32m     80\u001b[0m                                &(self.edge_index.t()[:,1] == v_j) ).nonzero().shape[0] == 1\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "path = osp.join(osp.abspath(''), '..', 'data', 'PPI')\n",
    "\n",
    "train_dataset = PPI(path, split='train')\n",
    "valid_dataset = PPI(path, split='val')\n",
    "test__dataset = PPI(path, split='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False)\n",
    "test__loader = DataLoader(test__dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "intrain = True\n",
    "\n",
    "class testNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testNet, self).__init__()\n",
    "        self.conv1 = GCNConv(train_dataset.num_features, 256)\n",
    "        self.conv2 = GCNConv(256, train_dataset.num_classes)\n",
    "    def forward(self, x, edge_index):\n",
    "        # self.hag = HAG(x, edge_index, ha_proportion=0.1)\n",
    "        # build hag\n",
    "        # self.hag.graph_to_hag()\n",
    "        # self.hag.h = self.conv1(self.hag.h, self.hag.edge_index)\n",
    "        # self.hag.h = F.leaky_relu(self.hag.h)\n",
    "        # self.hag.h = F.dropout(self.hag.h, training=intrain)\n",
    "        # aggregated node update\n",
    "        # self.hag.hag_aggregate()\n",
    "        # self.hag.h = self.conv2(self.hag.h, edge_index)\n",
    "        # self.hag.h = F.log_softmax(self.hag.h, dim=1)\n",
    "        # return self.hag.h[:self.hag.V]\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, training=intrain)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = testNet().to(device)\n",
    "loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        num_graphs = data.num_graphs\n",
    "        data.batch = None\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_op(model(data.x, data.edge_index), data.y)\n",
    "        total_loss += loss.item() * num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "loss = train()\n",
    "\n",
    "# val_f1 = test(val_loader)\n",
    "# test_f1 = test(test_loader)\n",
    "# print('Epoch: {:02d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'.format(epoch, loss, val_f1, test_f1))\n",
    "\n",
    "print('Loss: {:.4f}'.format(loss))\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     hag = HAG(batch.x, batch.edge_index)\n",
    "#     hag.graph_to_hag()\n",
    "# #     for i in range(5):\n",
    "# #         hag.hag_aggregate()\n",
    "#     print(batch.x.shape[0])\n",
    "#     print(hag.capacity)\n",
    "#     print(hag.h.shape[0])\n",
    "#     print(hag.V)\n",
    "#     print(hag.x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1, 1],\n",
       "       [2, 3, 1, 1],\n",
       "       [1, 1, 2, 2],\n",
       "       [1, 1, 2, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "m = np.array([\n",
    "    [0,1,1,1],\n",
    "    [1,0,1,1],\n",
    "    [1,1,0,0],\n",
    "    [1,1,0,0]\n",
    "])\n",
    "# c = np.array([0,1,2])\n",
    "m.dot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 7, 7],\n",
       "        [1, 0, 7, 6],\n",
       "        [5, 1, 0, 6],\n",
       "        [5, 3, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.array([\n",
    "    [0,1,5,5],\n",
    "    [1,0,1,3],\n",
    "    [7,7,0,0],\n",
    "    [7,6,6,0]\n",
    "])\n",
    "csr_m = sp.sparse.csr_matrix(m)\n",
    "csr_m.transpose().todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_m = sp.sparse.csr_matrix(m).dot(sp.sparse.csr_matrix(m))#.todense()\n",
    "print(csr_m.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_m.setdiag(0)\n",
    "print(csr_m.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = csr_m.argmax()\n",
    "(int(max_num/csr_m.get_shape()[0]), int(max_num%csr_m.get_shape()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_m.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.log2(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "b = a[0] + a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.view(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.view(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([c[:1],c[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-env",
   "language": "python",
   "name": "gnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
